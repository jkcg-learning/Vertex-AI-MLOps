{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FZxMEEIWygAg",
        "FTL5tzhSXRpG",
        "c4_93MkF369u",
        "veJ5zQOxSqPJ",
        "YIqsDew7Yn1o",
        "IZhGKvIO0FKu",
        "Vx9r4CJg2xkY",
        "7JGm1YhnUExE",
        "UJL5drQCU3TO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T4zN58itdrR"
      },
      "source": [
        "# Vertex AI Pipelines\n",
        "\n",
        "Great to have you here\n",
        "\n",
        "This notebook is part of a article about Vertex AI Pipelines. If you want to get more background information head over to the article. \n",
        "\n",
        "* üìñ Article: https://medium.com/google-cloud/google-vertex-ai-the-easiest-way-to-run-ml-pipelines-3a41c5ed153\n",
        "* üé• Video: https://www.youtube.com/watch?v=gtVHw5YCRhE\n",
        "\n",
        "Your feedback and questions are highly appreciated. <br>You can find me on Twitter [@HeyerSascha](https://twitter.com/HeyerSascha) or connect with me via [LinkedIn](https://www.linkedin.com/in/saschaheyer/). <br>Even better, subscribe to my [YouTube](https://www.youtube.com/channel/UC--Sm3D-rqCUeLXmraypdPQ) channel ‚ù§Ô∏è."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/gtVHw5YCRhE\" title=\"YouTube video player\" frameborder=\"0\" allowfullscreen></iframe>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "4dDbBwOzLnej",
        "outputId": "f7417fb2-b30d-4625-bdb5-0c1cfea9830e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/gtVHw5YCRhE\" title=\"YouTube video player\" frameborder=\"0\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqB5XvP-U3Sn"
      },
      "source": [
        "# Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5UmtuvhYixkz",
        "outputId": "05c7e2fd-8521-49ee-dfed-7372c110cb7c"
      },
      "source": [
        "# updated to the latest dependencies on February 2023\n",
        "!pip install google-cloud-aiplatform==1.21.0 --upgrade\n",
        "!pip install google-cloud-pipeline-components==1.0.27 --upgrade\n",
        "!pip install kfp==1.8.16 --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-aiplatform==1.21.0\n",
            "  Downloading google_cloud_aiplatform-1.21.0-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (2.34.4)\n",
            "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (21.3)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (2.11.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (3.19.6)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (1.8.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (1.22.2)\n",
            "Collecting shapely<2.0.0\n",
            "  Downloading Shapely-1.8.5.post1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform==1.21.0) (2.7.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (2.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (1.58.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (1.51.1)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (1.48.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.21.0) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.21.0) (2.8.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.21.0) (2.3.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.8/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.21.0) (0.12.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform==1.21.0) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (5.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.21.0) (1.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.21.0) (0.4.8)\n",
            "Installing collected packages: shapely, google-cloud-aiplatform\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.1\n",
            "    Uninstalling shapely-2.0.1:\n",
            "      Successfully uninstalled shapely-2.0.1\n",
            "  Attempting uninstall: google-cloud-aiplatform\n",
            "    Found existing installation: google-cloud-aiplatform 1.19.0\n",
            "    Uninstalling google-cloud-aiplatform-1.19.0:\n",
            "      Successfully uninstalled google-cloud-aiplatform-1.19.0\n",
            "Successfully installed google-cloud-aiplatform-1.21.0 shapely-1.8.5.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "shapely"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-cloud-pipeline-components==1.0.27 in /usr/local/lib/python3.8/dist-packages (1.0.27)\n",
            "Requirement already satisfied: google-cloud-notebooks>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pipeline-components==1.0.27) (1.6.1)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pipeline-components==1.0.27) (2.7.0)\n",
            "Requirement already satisfied: kfp>=1.8.9 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pipeline-components==1.0.27) (1.8.16)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2,>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pipeline-components==1.0.27) (1.21.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-pipeline-components==1.0.27) (2.11.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (2.25.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (1.58.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (3.19.6)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (2.16.0)\n",
            "Requirement already satisfied: shapely<2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (1.8.5.post1)\n",
            "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (21.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (1.22.2)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (2.34.4)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (1.8.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.8/dist-packages (from google-cloud-notebooks>=0.4.0->google-cloud-pipeline-components==1.0.27) (0.12.6)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage<3,>=1.20.0->google-cloud-pipeline-components==1.0.27) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage<3,>=1.20.0->google-cloud-pipeline-components==1.0.27) (2.4.1)\n",
            "Requirement already satisfied: fire<1,>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.5.0)\n",
            "Requirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.4.0)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.2 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.10.4)\n",
            "Requirement already satisfied: Deprecated<2,>=1.2.7 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.2.13)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (2.2.1)\n",
            "Requirement already satisfied: kubernetes<19,>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (18.20.0)\n",
            "Requirement already satisfied: jsonschema<4,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (3.2.0)\n",
            "Requirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (3.0.1)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.12.11)\n",
            "Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.8.10)\n",
            "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.1.16)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.15)\n",
            "Requirement already satisfied: PyYAML<6,>=5.3 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (4.4.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.7.0)\n",
            "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (7.1.2)\n",
            "Requirement already satisfied: strip-hints<1,>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.1.10)\n",
            "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.8.5)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.10.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated<2,>=1.2.7->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire<1,>=0.3.1->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire<1,>=0.3.1->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (2.2.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (1.48.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (1.51.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client<2,>=1.7.8->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client<2,>=1.7.8->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (2.8.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3,>=1.20.0->google-cloud-pipeline-components==1.0.27) (1.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.19.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.8/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.8/dist-packages (from kubernetes<19,>=8.0.0->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.3.1)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from kubernetes<19,>=8.0.0->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (1.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components==1.0.27) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (4.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from strip-hints<1,>=0.1.8->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (0.38.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components==1.0.27) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp>=1.8.9->google-cloud-pipeline-components==1.0.27) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kfp==1.8.16 in /usr/local/lib/python3.8/dist-packages (1.8.16)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (1.12.11)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (2.11.0)\n",
            "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.1.16)\n",
            "Requirement already satisfied: jsonschema<4,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (3.2.0)\n",
            "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (7.1.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.7.0)\n",
            "Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.8.10)\n",
            "Requirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (2.16.0)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (2.2.1)\n",
            "Requirement already satisfied: Deprecated<2,>=1.2.7 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (1.2.13)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (2.7.0)\n",
            "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (1.8.5)\n",
            "Requirement already satisfied: strip-hints<1,>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.1.10)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.10.1)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.15)\n",
            "Requirement already satisfied: kubernetes<19,>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (18.20.0)\n",
            "Requirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (4.4.0)\n",
            "Requirement already satisfied: fire<1,>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (0.5.0)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.2 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (1.10.4)\n",
            "Requirement already satisfied: PyYAML<6,>=5.3 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (5.4.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.13.0 in /usr/local/lib/python3.8/dist-packages (from kfp==1.8.16) (3.19.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated<2,>=1.2.7->kfp==1.8.16) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire<1,>=0.3.1->kfp==1.8.16) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire<1,>=0.3.1->kfp==1.8.16) (2.2.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.16) (2.25.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.16) (1.58.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.16) (0.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.16) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.1->kfp==1.8.16) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.1->kfp==1.8.16) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.1->kfp==1.8.16) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage<3,>=1.20.0->kfp==1.8.16) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage<3,>=1.20.0->kfp==1.8.16) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp==1.8.16) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp==1.8.16) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp==1.8.16) (0.19.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.16) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.8/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.16) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.16) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.8/dist-packages (from kubernetes<19,>=8.0.0->kfp==1.8.16) (1.3.1)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from kubernetes<19,>=8.0.0->kfp==1.8.16) (1.5.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from strip-hints<1,>=0.1.8->kfp==1.8.16) (0.38.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3,>=1.20.0->kfp==1.8.16) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp==1.8.16) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.16) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.16) (4.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp==1.8.16) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtTT_nZzevNK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyao5kfylbI"
      },
      "source": [
        "**Please restart your Colab runtime before importing the modules**\n",
        "\n",
        "Otherwise you might get a version conflict related error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mcs7B5VUox_"
      },
      "source": [
        "import kfp\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2.dsl import pipeline\n",
        "from kfp.v2.dsl import component\n",
        "from kfp.v2.dsl import OutputPath\n",
        "from kfp.v2.dsl import InputPath\n",
        "\n",
        "from kfp.v2.dsl import Output\n",
        "from kfp.v2.dsl import Metrics\n",
        "\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "\n",
        "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
        "\n",
        "from google_cloud_pipeline_components.v1.model import ModelUploadOp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L21RLrfDFdcE"
      },
      "source": [
        "# Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0RNBXMlf3Gl",
        "outputId": "0816a8c5-9d93-4c62-cb78-af1926f88512"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "credentials = auth._check_adc()\n",
        "print(credentials)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGReMEivS070"
      },
      "source": [
        "set the project id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYz_UaJ1S0QX"
      },
      "source": [
        "PROJECT_ID = \"sascha-playground-doit\"\n",
        "PIPELINE_ROOT = \"gs://doit-vertex-demo/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD8XJufeSDAm"
      },
      "source": [
        "# Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5AkYzaFb3Q"
      },
      "source": [
        "# use this instead\n",
        "aiplatform.init(project=PROJECT_ID,\n",
        "                location='us-central1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCSPjj-D4Fao"
      },
      "source": [
        "# Pipeline Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gyZkv8xyenN"
      },
      "source": [
        "## Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onddQwd1U1qR"
      },
      "source": [
        "@component() \n",
        "def concat(a: str, b: str) -> str:\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma7xWwLLVSlr"
      },
      "source": [
        "@component\n",
        "def reverse(a: str)->NamedTuple(\"outputs\", [(\"before\", str), (\"after\", str)]):\n",
        "  return a, a[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZxMEEIWygAg"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUrZade1VZGy"
      },
      "source": [
        "@pipeline(name=\"basic-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"basic-pipeline\")\n",
        "def basic_pipeline(a: str='stres', b: str='sed'):\n",
        "    concat_task = concat(a, b)\n",
        "    reverse_task = reverse(concat_task.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTL5tzhSXRpG"
      },
      "source": [
        "## Compile\n",
        "\n",
        "The compiler takes our pipeline function and compiles it into our pipeline specifiction as json file. This json file we can use to create our pipeline in Vertex AI Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF0r0-CwVgpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b689df-cce4-46fb-9fc2-49ec25c8c95a"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "pipeline_func=basic_pipeline, package_path=\"basic_pipeline.json\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/kfp/v2/compiler/compiler.py:1290: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4_93MkF369u"
      },
      "source": [
        "## Run\n",
        "\n",
        "Create the run job using the API. \n",
        "You can also directly upload the pipeline JSON file in the Vertx AI UI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwlXs0reY56x"
      },
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"basic-pipeline\",\n",
        "    template_path=\"basic_pipeline.json\",\n",
        "    parameter_values={\"a\": \"stres\", \"b\": \"sed\"}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aogrQzmBZs7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7ab9ae-2c38-42f6-fff4-fd261fdb947b"
      },
      "source": [
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineJob created. Resource name: projects/234439745674/locations/us-central1/pipelineJobs/basic-pipeline-20230216075123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/234439745674/locations/us-central1/pipelineJobs/basic-pipeline-20230216075123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use this PipelineJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_job = aiplatform.PipelineJob.get('projects/234439745674/locations/us-central1/pipelineJobs/basic-pipeline-20230216075123')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/234439745674/locations/us-central1/pipelineJobs/basic-pipeline-20230216075123')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/basic-pipeline-20230216075123?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/basic-pipeline-20230216075123?project=234439745674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFlc7P5BTstS"
      },
      "source": [
        "# Is There More? I Want to Learn the Honest Stuff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veJ5zQOxSqPJ"
      },
      "source": [
        "## Component Specification (function based component)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1zyzD1-Ssi2"
      },
      "source": [
        "@component(output_component_file=\"concat_component.yaml\") \n",
        "def concat(a: str, b: str) -> str:\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzHM-vQ2T82E",
        "outputId": "6e559f61-031e-4c16-ad15-25543ca6a5d3"
      },
      "source": [
        "!cat ./concat_component.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: Concat\n",
            "inputs:\n",
            "- {name: a, type: String}\n",
            "- {name: b, type: String}\n",
            "outputs:\n",
            "- {name: Output, type: String}\n",
            "implementation:\n",
            "  container:\n",
            "    image: python:3.7\n",
            "    command:\n",
            "    - sh\n",
            "    - -c\n",
            "    - |2\n",
            "\n",
            "      if ! [ -x \"$(command -v pip)\" ]; then\n",
            "          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\n",
            "      fi\n",
            "\n",
            "      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12' && \"$0\" \"$@\"\n",
            "    - sh\n",
            "    - -ec\n",
            "    - |\n",
            "      program_path=$(mktemp -d)\n",
            "      printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "      python3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "    - |2+\n",
            "\n",
            "      import kfp\n",
            "      from kfp.v2 import dsl\n",
            "      from kfp.v2.dsl import *\n",
            "      from typing import *\n",
            "\n",
            "      def concat(a: str, b: str) -> str:\n",
            "        return a + b\n",
            "\n",
            "    args:\n",
            "    - --executor_input\n",
            "    - {executorInput: null}\n",
            "    - --function_to_execute\n",
            "    - concat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqsDew7Yn1o"
      },
      "source": [
        "## Share components\n",
        "In this example we use the component specification created based on a function based component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW-PsUmPYuFo"
      },
      "source": [
        "@pipeline(name=\"share-component\", \n",
        "          pipeline_root=PIPELINE_ROOT + \"share-component-pipeine\")\n",
        "def share_component_pipeline(a: str='stres', b: str='sed'):\n",
        "    #concat_op = concat(a, b)\n",
        "    concat_component = kfp.components.load_component_from_file('./concat_component.yaml')\n",
        "\n",
        "    concat_task = concat_component(a,b)\n",
        "    reverse_task = reverse(concat_task.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmW81e_WZ1mZ",
        "outputId": "2f25c05a-a0d3-447a-eb5f-aec7bba84233"
      },
      "source": [
        "# just the usual boilerplate code to run the pipeline\n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=share_component_pipeline, package_path=\"share_component_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"share-component-pipeline\",\n",
        "    template_path=\"share_component_pipeline.json\",\n",
        "    parameter_values={\"a\": \"stres\", \"b\": \"sed\"}\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKvcwXX4KDe"
      },
      "source": [
        "## Pipeline with GPU and machine type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxntLJgD4l45"
      },
      "source": [
        "The following is an example how you can add an GPU to your component. For example the training componentn that needs access to accelerators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v231zyV4MUO"
      },
      "source": [
        "@component(output_component_file=\"gpu_training.yaml\", \n",
        "           base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\") \n",
        "def gpuTrainingFunc() -> bool:\n",
        "  import logging\n",
        "  import tensorflow as tf\n",
        "\n",
        "  gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "  for gpu in gpus:\n",
        "    logging.info('Name: {} Type: {}'.format(gpu.name, gpu.device_type))\n",
        "  \n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_qYZE-6Nfn"
      },
      "source": [
        "@pipeline(name=\"gpu-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"gpu-pipeline\")\n",
        "def gpu_pipeline():\n",
        "    gpuTraining = gpuTrainingFunc().add_node_selector_constraint(\n",
        "        label_name=\"cloud.google.com/gke-accelerator\", \n",
        "        value=\"NVIDIA_TESLA_T4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRXVqzdi7rdD",
        "outputId": "e02bc6fc-68f5-47f9-92e7-da07ef6f8393"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "  pipeline_func=gpu_pipeline, package_path=\"gpu_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "   display_name=\"gpu-pipeline\",\n",
        "   template_path=\"gpu_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZhGKvIO0FKu"
      },
      "source": [
        "## Schedule \n",
        "switch over to GCP and check your Cloud Functions and Cloud Scheduler ;)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deprecated don't use this anymore\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "api_client = AIPlatformClient(project_id=PROJECT_ID,\n",
        "                              region='us-central1')\n"
      ],
      "metadata": {
        "id": "l3OvzW_e0bBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YtB-uUp0ILg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b3c398-5060-48fb-9bc1-73429270fe6f"
      },
      "source": [
        "from kfp.v2.google.client import AIPlatformClient\n",
        "api_client = AIPlatformClient(project_id=PROJECT_ID, region='us-central1')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "QVVt4S130Vrz",
        "outputId": "24e312e3-7a4c-4201-fe07-3d6f3c553752"
      },
      "source": [
        "api_client.create_schedule_from_job_spec(\n",
        "    job_spec_path='basic_pipeline.json',\n",
        "    schedule='*/10 * * * *' # every 10 minutes\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/schedule.py\u001b[0m in \u001b[0;36m_create_from_pipeline_dict\u001b[0;34m(pipeline_dict, schedule, project_id, region, time_zone, parameter_values, pipeline_root, service_account, app_engine_region, cloud_scheduler_service_account)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mproject_location_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_location_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mjob_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduled_job\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/schedule.py\u001b[0m in \u001b[0;36m_create_scheduler_job\u001b[0;34m(project_location_path, job_body)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_location_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     ).execute()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 409 when requesting https://cloudscheduler.googleapis.com/v1/projects/sascha-playground-doit/locations/us-central1/jobs?alt=json returned \"Job projects/sascha-playground-doit/locations/us-central1/jobs/pipeline_basic-pipeline_9d348449_div10-a-a-a-a already exists.\". Details: \"Job projects/sascha-playground-doit/locations/us-central1/jobs/pipeline_basic-pipeline_9d348449_div10-a-a-a-a already exists.\">",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-adcd945c64a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m api_client.create_schedule_from_job_spec(\n\u001b[1;32m      2\u001b[0m     \u001b[0mjob_spec_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'basic_pipeline.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*/10 * * * *'\u001b[0m \u001b[0;31m# every 10 minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py\u001b[0m in \u001b[0;36mcreate_schedule_from_job_spec\u001b[0;34m(self, job_spec_path, schedule, time_zone, pipeline_root, parameter_values, service_account, enable_caching, app_engine_region, cloud_scheduler_service_account)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mapp_engine_region\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp_engine_region\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             cloud_scheduler_service_account=cloud_scheduler_service_account)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/schedule.py\u001b[0m in \u001b[0;36m_create_from_pipeline_dict\u001b[0;34m(pipeline_dict, schedule, project_id, region, time_zone, parameter_values, pipeline_root, service_account, app_engine_region, cloud_scheduler_service_account)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'409'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             raise RuntimeError(\n\u001b[0;32m--> 201\u001b[0;31m                 'The exact same schedule already exists') from err\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The exact same schedule already exists"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9r4CJg2xkY"
      },
      "source": [
        "## Additional Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al_sL-1f2zYK"
      },
      "source": [
        "@component(packages_to_install = [\"pandas==1.3.4\"],) \n",
        "def additional_packages():\n",
        "  import pandas\n",
        "  print(pandas.__version__)\n",
        "\n",
        "# fails for demonstration purposes\n",
        "@component() \n",
        "def additional_packages_missing():\n",
        "  import pandas\n",
        "  print(pandas.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJl27Itt3iCw",
        "outputId": "2707b7e5-bdc4-4533-f23f-cdd0242ca61c"
      },
      "source": [
        "@pipeline(name=\"additional-packages-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"additional-packages-pipeline\")\n",
        "def additional_packges_pipeline():\n",
        "    additional_packages_task = additional_packages()\n",
        "    additional_packages_missing_task = additional_packages_missing()\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=additional_packges_pipeline, package_path=\"additional_packages_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"additional-packages-pipeline\",\n",
        "    template_path=\"additional_packages_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-sEJmKq6msb"
      },
      "source": [
        "## Base Image\n",
        "\n",
        "Compare the component specification yaml and find the difference\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/training/pre-built-containers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ1P8F826sjO"
      },
      "source": [
        "@component(output_component_file=\"custom_base_image_component.yaml\",\n",
        "           base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\"\n",
        ") \n",
        "def custom_base_image():\n",
        "  import tensorflow as tf\n",
        "  print(tf.version.VERSION)\n",
        "\n",
        "# fails for demonstration purposes\n",
        "@component(output_component_file=\"default_base_image_component.yaml\") \n",
        "def default_base_image():\n",
        "  import tensorflow as tf\n",
        "  print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOnGZ59z64Y_",
        "outputId": "71e12312-bd5f-484b-8a77-d40f8dda586c"
      },
      "source": [
        "!cat ./default_base_image_component.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: Default base image\n",
            "implementation:\n",
            "  container:\n",
            "    image: python:3.7\n",
            "    command:\n",
            "    - sh\n",
            "    - -c\n",
            "    - |2\n",
            "\n",
            "      if ! [ -x \"$(command -v pip)\" ]; then\n",
            "          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\n",
            "      fi\n",
            "\n",
            "      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12' && \"$0\" \"$@\"\n",
            "    - sh\n",
            "    - -ec\n",
            "    - |\n",
            "      program_path=$(mktemp -d)\n",
            "      printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "      python3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "    - |2+\n",
            "\n",
            "      import kfp\n",
            "      from kfp.v2 import dsl\n",
            "      from kfp.v2.dsl import *\n",
            "      from typing import *\n",
            "\n",
            "      def default_base_image():\n",
            "        import tensorflow as tf\n",
            "        print(tf.version.VERSION)\n",
            "\n",
            "    args:\n",
            "    - --executor_input\n",
            "    - {executorInput: null}\n",
            "    - --function_to_execute\n",
            "    - default_base_image\n",
            "PipelineJob projects/234439745674/locations/us-central1/pipelineJobs/gpu-pipeline-20220615205633 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9EgmAoq7DAa",
        "outputId": "d6102ed9-c2ab-4b71-9b09-4eded35fc6cc"
      },
      "source": [
        "!cat ./custom_base_image_component.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: Custom base image\n",
            "implementation:\n",
            "  container:\n",
            "    image: gcr.io/deeplearning-platform-release/tf2-gpu.2-6\n",
            "    command:\n",
            "    - sh\n",
            "    - -c\n",
            "    - |2\n",
            "\n",
            "      if ! [ -x \"$(command -v pip)\" ]; then\n",
            "          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\n",
            "      fi\n",
            "\n",
            "      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12' && \"$0\" \"$@\"\n",
            "    - sh\n",
            "    - -ec\n",
            "    - |\n",
            "      program_path=$(mktemp -d)\n",
            "      printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "      python3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "    - |2+\n",
            "\n",
            "      import kfp\n",
            "      from kfp.v2 import dsl\n",
            "      from kfp.v2.dsl import *\n",
            "      from typing import *\n",
            "\n",
            "      def custom_base_image():\n",
            "        import tensorflow as tf\n",
            "        print(tf.version.VERSION)\n",
            "\n",
            "    args:\n",
            "    - --executor_input\n",
            "    - {executorInput: null}\n",
            "    - --function_to_execute\n",
            "    - custom_base_image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JGm1YhnUExE"
      },
      "source": [
        "## Predefined Components\n",
        "\n",
        "For a full list of pre-defined components see https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list\n",
        "\n",
        "Predefined components depends on the use case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckZCJavxBtf7"
      },
      "source": [
        "# Pipeline end to end (XGBoost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCymNXQuW15K"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJqZSzYBu2y"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2 import dsl\n",
        "from kfp.v2.dsl import (Artifact,\n",
        "                        Dataset,\n",
        "                        Input,\n",
        "                        Model,\n",
        "                        Output,\n",
        "                        Metrics,\n",
        "                        ClassificationMetrics,\n",
        "                        component, \n",
        "                        Markdown)\n",
        "\n",
        "from kfp.v2 import compiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6O8akfmUoWc"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPKVVep2BxU9"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"scikit-learn==1.0.1\",\n",
        "    ],\n",
        ")\n",
        "def get_data(\n",
        "    dataset_train: Output[Dataset],\n",
        "    dataset_test: Output[Dataset],\n",
        "):\n",
        "    \n",
        "    from sklearn import datasets\n",
        "    from sklearn.model_selection import train_test_split as tts\n",
        "    import pandas as pd\n",
        "\n",
        "\n",
        "    # dataset https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
        "    data_raw = datasets.load_breast_cancer()\n",
        "    data = pd.DataFrame(data_raw.data, columns=data_raw.feature_names)\n",
        "    data[\"target\"] = data_raw.target\n",
        "    \n",
        "    train, test = tts(data, test_size=0.3)\n",
        "    \n",
        "    train.to_csv(dataset_train.path)\n",
        "    test.to_csv(dataset_test.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmllUUq0UqDo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aVHg2lSByxy"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"xgboost==1.5.1\",\n",
        "        \"scikit-learn==1.0.1\", #xgboost requires scikitlearn\n",
        "    ],\n",
        ")\n",
        "def train_model(\n",
        "    dataset: Input[Dataset],\n",
        "    model_artifact: Output[Model]\n",
        "):\n",
        "    \n",
        "    from xgboost import XGBClassifier\n",
        "    import pandas as pd\n",
        "    \n",
        "    data = pd.read_csv(dataset.path)\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective=\"binary:logistic\"\n",
        "    )\n",
        "    model.fit(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "\n",
        "    score = model.score(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "\n",
        "    model_artifact.metadata[\"train_score\"] = float(score)\n",
        "    model_artifact.metadata[\"framework\"] = \"XGBoost\"\n",
        "\n",
        "    print(model_artifact.path)\n",
        "    \n",
        "    model.save_model(model_artifact.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkazD35dv0Un"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1AiObLIB1cx"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"scikit-learn==1.0.1\",\n",
        "        \"xgboost==1.5.1\"\n",
        "    ],\n",
        ")\n",
        "def eval_model(\n",
        "    test_set: Input[Dataset],\n",
        "    xgb_model: Input[Model],\n",
        "    metrics: Output[ClassificationMetrics],\n",
        "    smetrics: Output[Metrics]\n",
        ") -> NamedTuple(\"Outputs\", [(\"deploy\", str)]): \n",
        "    from xgboost import XGBClassifier\n",
        "    import pandas as pd\n",
        "    \n",
        "    data = pd.read_csv(test_set.path)\n",
        "    model = XGBClassifier()\n",
        "    model.load_model(xgb_model.path)\n",
        "    \n",
        "    score = model.score(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "    \n",
        "    from sklearn.metrics import roc_curve\n",
        "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(\n",
        "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
        "    )\n",
        "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
        "    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    y_pred = model.predict(data.drop(columns=[\"target\"]))\n",
        "    \n",
        "    metrics.log_confusion_matrix(\n",
        "       [\"False\", \"True\"],\n",
        "       confusion_matrix(\n",
        "           data.target, y_pred\n",
        "       ).tolist()\n",
        "    )\n",
        "    \n",
        "    xgb_model.metadata[\"test_score\"] = float(score)\n",
        "    smetrics.log_metric(\"score\", float(score))\n",
        "\n",
        "\n",
        "    deploy = \"true\"\n",
        "    #compare threshold or to previous\n",
        "\n",
        "    return (deploy,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4qRVZ9Jv2NV"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZq-EaJngwFW"
      },
      "source": [
        "@component(packages_to_install=[\"google-cloud-aiplatform==1.3.0\"])\n",
        "def deploy(\n",
        "    model: Input[Model],\n",
        "    project: str,\n",
        "    region: str,):\n",
        "  \n",
        "  import logging\n",
        "  from google.cloud import aiplatform\n",
        "  aiplatform.init(project=project, location=region)\n",
        "\n",
        "  logging.basicConfig(level=logging.DEBUG)\n",
        "  logging.debug(model)\n",
        "\n",
        "  print(model)\n",
        "  print(model.uri)\n",
        "\n",
        "  import os\n",
        "  path,file = os.path.split(model.uri)\n",
        "\n",
        "  import datetime\n",
        "  \n",
        "  # datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "  # serving image https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#xgboost\n",
        "  deployed_model = aiplatform.Model.upload(\n",
        "        display_name=\"xgboost-pipeline\",\n",
        "        artifact_uri = path,\n",
        "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest\"\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgW9szKv46I"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8JS0BA0B7za"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT + \"xgboost-pipeline\",\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name=\"xgboost-pipeline-with-deployment\",\n",
        ")\n",
        "def pipeline():\n",
        "    dataset_op = get_data()\n",
        "    training_op = train_model(dataset_op.outputs[\"dataset_train\"])\n",
        "    eval_op = eval_model(\n",
        "        test_set=dataset_op.outputs[\"dataset_test\"],\n",
        "        xgb_model=training_op.outputs[\"model_artifact\"]\n",
        "    )\n",
        "\n",
        "    with dsl.Condition(\n",
        "        eval_op.outputs[\"deploy\"] == \"true\",\n",
        "        name=\"deploy\",\n",
        "    ):\n",
        "\n",
        "      deploy_op = deploy(training_op.outputs[\"model_artifact\"], \n",
        "                         'sascha-playground-doit',\n",
        "                         'us-central1')\n",
        "\n",
        "    # we need a solution for xgb models\n",
        "    # its here https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#aiplatform_deploy_model_custom_trained_model_sample-python\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15juxBrzgiLk"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfz5joUmghwp",
        "outputId": "708f3444-2301-4fc4-8781-915f5fd9c8fd"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline,\n",
        "    package_path='xgb_pipeline.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJL5drQCU3TO"
      },
      "source": [
        "## Run Pipeline (old soon deprectated)\n",
        "deprectation see https://github.com/kubeflow/pipelines/blob/56cf094fd3058b5c640077968ffb0f01e0511a57/sdk/python/kfp/v2/google/client/client.py#L169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IS2DvPDSB_FG",
        "outputId": "f8489bd1-9930-4949-c223-f1100d1f4da4"
      },
      "source": [
        "response = api_client.create_run_from_job_spec(\n",
        "    'xgb_pipeline.json',\n",
        "    enable_caching=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/xgboost-pipeline-with-deployment-20211207103057?project=sascha-playground-doit\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSDY3Rrh8OTq"
      },
      "source": [
        "## Run Pipeline (new)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g0qJwcG8QHK",
        "outputId": "aaefdb7d-0962-49f0-d7f5-270794e1dce9"
      },
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"xgb-pipeline\",\n",
        "    template_path=\"xgb_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm-Vxnc58cIx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline end to end (Huggingface, Sentiment)\n",
        "Work in progress"
      ],
      "metadata": {
        "id": "CQgfRlEoMdP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "vfu406NnMoP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kfp\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2.dsl import pipeline\n",
        "from kfp.v2.dsl import component\n",
        "from kfp.v2.dsl import OutputPath\n",
        "from kfp.v2.dsl import InputPath\n",
        "\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2 import dsl\n",
        "from kfp.v2.dsl import (Artifact,\n",
        "                        Dataset,\n",
        "                        Input,\n",
        "                        Model,\n",
        "                        Output,\n",
        "                        Metrics,\n",
        "                        ClassificationMetrics,\n",
        "                        component, \n",
        "                        Markdown)\n",
        "\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "\n",
        "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
        "\n",
        "from google_cloud_pipeline_components.v1.model import ModelUploadOp"
      ],
      "metadata": {
        "id": "9UUEt5Y7NBqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"sascha-playground-doit\"\n",
        "PIPELINE_ROOT = \"gs://doit-vertex-demo/\""
      ],
      "metadata": {
        "id": "EacI7gQ6NDWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this instead\n",
        "aiplatform.init(project=PROJECT_ID,\n",
        "                location='us-central1')"
      ],
      "metadata": {
        "id": "OCrjJKg6NEap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "ByOiC-yKMp7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"transformers==4.1.1\",\n",
        "        \"google-cloud-storage==1.35.0\",\n",
        "        \"scikit-learn==0.24.0\", \n",
        "        \"pandas==1.1.5\"\n",
        "    ],\n",
        "    base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\"\n",
        ")\n",
        "def train_model(\n",
        "    epochs: int,\n",
        "    model_artifact: Output[Model],\n",
        "    smetrics: Output[Metrics]\n",
        "):\n",
        "    \n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from transformers import DistilBertTokenizerFast\n",
        "    from transformers import TFDistilBertForSequenceClassification\n",
        "    from google.cloud import storage\n",
        "\n",
        "    import tensorflow as tf\n",
        "    import json\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from io import StringIO\n",
        "\n",
        "    print('load distilbert')\n",
        "    # load model and tokenizer\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\")\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "\n",
        "    print('start training')\n",
        "    file = tf.io.gfile.GFile(\n",
        "        'gs://machine-learning-samples/datasets/sentiment/imdb/csv/dataset.csv', mode='r').read()\n",
        "    df = pd.read_csv(StringIO(file))\n",
        "\n",
        "    #df = df.head()\n",
        "\n",
        "    sentiments = df['sentiment'].values.tolist()\n",
        "    reviews = df['review'].values.tolist()\n",
        "\n",
        "    training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(\n",
        "        reviews,\n",
        "        sentiments,\n",
        "        test_size=.2)\n",
        "\n",
        "    train_encodings = tokenizer(training_sentences,\n",
        "                                truncation=True,\n",
        "                                padding=True)\n",
        "    val_encodings = tokenizer(validation_sentences,\n",
        "                              truncation=True,\n",
        "                              padding=True)\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        dict(train_encodings),\n",
        "        training_labels\n",
        "    ))\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        dict(val_encodings),\n",
        "        validation_labels\n",
        "    ))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=model.compute_loss,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_dataset.shuffle(100).batch(16),\n",
        "              epochs=epochs,\n",
        "              batch_size=16,)\n",
        "\n",
        "    model.save_pretrained(model_artifact.path)\n",
        "    print(model_artifact.path)\n",
        "\n",
        "    print('eval')\n",
        "    evaluation = model.evaluate(val_dataset.shuffle(100).batch(16),\n",
        "               batch_size=16)\n",
        "    print(evaluation)\n",
        "\n",
        "    smetrics.log_metric(\"accuracy\", float(evaluation[1]))\n",
        "    "
      ],
      "metadata": {
        "id": "UMlUTgh3NFy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Serving Container\n",
        "code for the container see https://github.com/SaschaHeyer/serving-custom-container"
      ],
      "metadata": {
        "id": "kCY9KVu7MrDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(packages_to_install=[\n",
        "    \"google-cloud-build==3.8.3\",\n",
        "    \"google-api-python-client\"])\n",
        "def build_serving_container(model_artifact: Input[Model]) -> NamedTuple(\"Outputs\", [(\"container\", str)]): \n",
        "    from google.cloud.devtools import cloudbuild\n",
        "    from googleapiclient.discovery import build\n",
        "    import time\n",
        "\n",
        "    print('deploy.............')\n",
        "    print(model_artifact.uri)\n",
        "\n",
        "    client = cloudbuild.CloudBuildClient()\n",
        "    build = cloudbuild.Build()\n",
        "\n",
        "\n",
        "    # version is current timestamp \n",
        "    version = str(int(time.time()))\n",
        "    container = \"gcr.io/sascha-playground-doit/sentiment-fast-api-test:{}\".format(version)\n",
        "\n",
        "\n",
        "    #todo get the model from the pipeline folder\n",
        "    build.steps = [{\"name\": \"gcr.io/cloud-builders/git\",\n",
        "                    \"args\": [\"clone\", \"https://github.com/SaschaHeyer/serving-custom-container\"]}, \n",
        "                   {\"name\": \"gcr.io/cloud-builders/gsutil\",\n",
        "                    \"args\": [\"cp\", \"-r\", \"gs://doit-vertex-demo/models/sentiment\", \"./serving-custom-container\"]}, \n",
        "                   {\"name\": \"gcr.io/cloud-builders/docker\",\n",
        "                    \"args\": [\"build\", \"-t\", container, \"serving-custom-container\" ]},\n",
        "                   {\"name\": \"gcr.io/cloud-builders/docker\",\n",
        "                    \"args\": [\"push\", container]}]\n",
        "\n",
        "    #build.substitutions = {\"_VERSION\": version}\n",
        "\n",
        "    operation = client.create_build(project_id=\"sascha-playground-doit\", build=build)\n",
        "    # Print the in-progress operation\n",
        "    print(\"IN PROGRESS:\")\n",
        "    print(operation.metadata)\n",
        "\n",
        "    result = operation.result()\n",
        "    # Print the completed status\n",
        "    print(\"RESULT:\", result.status)\n",
        "\n",
        "    return (container,)"
      ],
      "metadata": {
        "id": "8J-Fbxo1NHYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy"
      ],
      "metadata": {
        "id": "kXG_ErEiMsyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component(packages_to_install=[\"google-cloud-aiplatform==1.15.0\"])\n",
        "def deploy_model(\n",
        "    project: str,\n",
        "    region: str,\n",
        "    container: str\n",
        "):\n",
        "  from google.cloud import aiplatform\n",
        "  aiplatform.init(project=project, location=region)\n",
        "\n",
        "  ENDPOINT_NAME = \"sentiment\"\n",
        "  DISPLAY_NAME  = \"sentiment\"\n",
        "\n",
        "  MODEL_TYPE = \"query\"\n",
        "  MODEL_NAME = f\"{MODEL_TYPE}_model\"  # Used by the deployment container.\n",
        "\n",
        "  def create_endpoint():\n",
        "    print('create endpoint')\n",
        "    endpoints = aiplatform.Endpoint.list(\n",
        "      filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n",
        "      order_by='create_time desc',\n",
        "      project=project, \n",
        "      location=region,\n",
        "    )\n",
        "\n",
        "    if len(endpoints) > 0:\n",
        "      endpoint = endpoints[0]  \n",
        "    else:\n",
        "      endpoint = aiplatform.Endpoint.create(\n",
        "        display_name=ENDPOINT_NAME, project=project, location=region\n",
        "      )\n",
        "\n",
        "    return endpoint\n",
        "\n",
        "  models = aiplatform.Model.list(filter=(\"display_name={}\").format(DISPLAY_NAME))\n",
        "\n",
        "  PORT = 80\n",
        "  HEALTH_ROUTE = \"/health\"\n",
        "  PREDICT_ROUTE = \"/predict\"\n",
        "\n",
        "\n",
        "  if len(models) == 0:\n",
        "    # upload the initial model\n",
        "    model_uploaded = aiplatform.Model.upload(\n",
        "          display_name = DISPLAY_NAME, \n",
        "          serving_container_image_uri = container,\n",
        "          serving_container_health_route=HEALTH_ROUTE,\n",
        "          serving_container_predict_route=PREDICT_ROUTE,   \n",
        "          serving_container_ports=[PORT]\n",
        "    )\n",
        "  else: \n",
        "    #upload a new model version using the exiting model ressource ID\n",
        "    parent_model = models[0].resource_name\n",
        "\n",
        "    model_uploaded = aiplatform.Model.upload(\n",
        "          parent_model = parent_model,\n",
        "          display_name = DISPLAY_NAME, \n",
        "          serving_container_image_uri = container,\n",
        "          serving_container_health_route=HEALTH_ROUTE,\n",
        "          serving_container_predict_route=PREDICT_ROUTE,   \n",
        "          serving_container_ports=[PORT]      \n",
        "    )\n",
        "\n",
        "  endpoint = create_endpoint() \n",
        "  \n",
        "  model_deploy = model_uploaded.deploy(\n",
        "        machine_type=\"n1-standard-4\", \n",
        "        endpoint=endpoint,\n",
        "        traffic_split={\"0\": 100},\n",
        "        deployed_model_display_name=DISPLAY_NAME,\n",
        "  )\n",
        "\n",
        "  # undeploy models without traffic for this specific endpoint\n",
        "  for model in endpoint.list_models():\n",
        "    print(model)\n",
        "    if model.id not in endpoint.traffic_split:\n",
        "      endpoint.undeploy(deployed_model_id = model.id)\n"
      ],
      "metadata": {
        "id": "jJtFKUurNQGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "CB20e-knMt3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT + \"sentiment-pipeline\",\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name=\"sentiment-pipeline\",\n",
        ")\n",
        "def pipeline(epochs:int):\n",
        "    train_op = train_model(epochs).add_node_selector_constraint(\n",
        "        label_name=\"cloud.google.com/gke-accelerator\", \n",
        "        value=\"NVIDIA_TESLA_T4\").set_caching_options(False)\n",
        "    \n",
        "    # build custom serving container with latest model\n",
        "    build_serving_container_op = build_serving_container(train_op.outputs[\"model_artifact\"]).set_caching_options(False)\n",
        "\n",
        "    # upload and deploy model to vertex ai\n",
        "    deploy_op = deploy_model(\"sascha-playground-doit\",\"us-central1\", build_serving_container_op.outputs[\"container\"])\n"
      ],
      "metadata": {
        "id": "f0dCWa5tNRzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile"
      ],
      "metadata": {
        "id": "jxDWoAwNMxqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline,\n",
        "    package_path='sentiment_pipeline.json')"
      ],
      "metadata": {
        "id": "ErZjGz6CNTWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b310c2d6-8225-4969-a078-e84b4052bf9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "e80cvl24Myrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"sentiment-pipeline\",\n",
        "    template_path=\"sentiment_pipeline.json\",\n",
        "    parameter_values={\n",
        "        'epochs': 3\n",
        "    }\n",
        ")\n",
        "\n",
        "job.submit(experiment=\"sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZrat10WNUyd",
        "outputId": "197e58d5-8123-4dac-ba7a-dc2af81b00e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineJob created. Resource name: projects/234439745674/locations/us-central1/pipelineJobs/sentiment-pipeline-20221123181836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/234439745674/locations/us-central1/pipelineJobs/sentiment-pipeline-20221123181836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use this PipelineJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_job = aiplatform.PipelineJob.get('projects/234439745674/locations/us-central1/pipelineJobs/sentiment-pipeline-20221123181836')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/234439745674/locations/us-central1/pipelineJobs/sentiment-pipeline-20221123181836')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/sentiment-pipeline-20221123181836?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/sentiment-pipeline-20221123181836?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Associating projects/234439745674/locations/us-central1/pipelineJobs/sentiment-pipeline-20221123181836 to Experiment: sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/234439745674/locations/us-central1/pipelineJobs/sentiment-pipeline-20221123181836 to Experiment: sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What about artifacts that are not a dataset or model?\n",
        "\n",
        "For that we can use outputPath which provides similar like the artifacts a path to Google Cloud Storage where we can store data. In any case you need to serialize any intermediate object from memory to save it as a file. In your next component you then can load the serialized file back to in memory object. "
      ],
      "metadata": {
        "id": "hA2zOlhZYBNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component() \n",
        "def first(output_path: OutputPath()):\n",
        "\n",
        "  # everything that can be serialized to a file can be stored\n",
        "  # you are not limited to the artifact types like dataset or model\n",
        "\n",
        "  # common cases are tfidf\n",
        " \n",
        "  animals = ['cat', 'dog']\n",
        "\n",
        "  import pickle\n",
        "\n",
        "  with open(output_path + \"animals.pkl\", 'wb') as file:\n",
        "    pickle.dump(animals, file)"
      ],
      "metadata": {
        "id": "1KWS9ZQyYL00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@component() \n",
        "def second(input_path: InputPath()):\n",
        "\n",
        "  import pickle\n",
        "  file = open(input_path + \"animals.pkl\", 'rb')\n",
        "  data = pickle.load(file)\n",
        "  file.close()\n",
        "\n",
        "  print(data)"
      ],
      "metadata": {
        "id": "S1EKc_9rYWHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(name=\"output-path-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"output-path-pipeline\")\n",
        "def output_pipeline():\n",
        "    first_task = first()\n",
        "    second_task = second(first_task.output)"
      ],
      "metadata": {
        "id": "ApQ80C7IaeiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiler.Compiler().compile(\n",
        "  pipeline_func=output_pipeline, package_path=\"output_pipeline.json\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtBerMSaa1UG",
        "outputId": "2988a385-3811-409b-e4b0-adfb5e7684f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"output-pipeline\",\n",
        "    template_path=\"output_pipeline.json\"\n",
        ")"
      ],
      "metadata": {
        "id": "7SmXK6aAbWdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job.run(sync=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aWXapX6btqp",
        "outputId": "89893fc8-4f33-4c4d-82e7-d90f9c7051fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31_R3lA-bxNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}